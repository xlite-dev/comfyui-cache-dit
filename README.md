# ComfyUI CacheDit 加速插件

一个为 ComfyUI 提供 diffusion 模型推理加速的简单有效插件。

## 🚀 特性

- **简单有效**：基于验证的缓存逻辑，无需复杂配置
- **显著加速**：在 FLUX 等模型上实现约 2x 推理加速
- **即插即用**：直接在 ComfyUI 工作流中使用
- **实时统计**：提供详细的性能统计信息

## 📦 安装

1. 将插件文件夹复制到 ComfyUI 的 `custom_nodes` 目录
2. 重启 ComfyUI

## 🔧 使用方法

1. 在工作流中添加 `CacheDit 模型加速` 节点
2. 将你的模型连接到该节点
3. 使用加速后的模型进行推理
![cachedit节点使用](./demo.png)

## 📊 工作原理

插件使用简单的缓存策略：
- 前 3 步正常计算（预热阶段）
- 之后每隔一步跳过计算，复用之前的结果
- 为缓存结果添加微量噪声防止图像伪影

这种方法利用了 diffusion 模型中相邻推理步骤输出相似的特性。

## ⚡ 性能表现

- **FLUX 模型**：约 2x 加速
- **缓存命中率**：理论 50%（实际略低）
- **质量损失**：极小，肉眼几乎无法察觉

## 🛠 故障排除

如果插件无法正常工作：
1. 检查控制台输出中的调试信息
2. 确认模型类型是否支持（主要支持 transformer 架构）
3. 查看统计信息确认缓存是否生效

## 📄 许可


开源项目，欢迎贡献和改进。
